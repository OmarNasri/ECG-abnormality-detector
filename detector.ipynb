{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG abnormality detector\n",
    "\n",
    "## Authors\n",
    "Sini LÃ¤hde <br>\n",
    "Omar Nasri <br>\n",
    "Juuso Torikka\n",
    "\n",
    "### Objective\n",
    "\n",
    "Objective of this notebook is to demonstrate arrhythmia \n",
    "detection from ECG signals. <br>\n",
    "This notebook contains all relevant functions \n",
    "and functionalities for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/wrfllc_x5z5bnp2dcbrj_0900000gn/T/ipykernel_11013/2673367821.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = \"data_sources\"\n",
    "NORMAL_DATA = \"normal\"\n",
    "ABNORMAL_DATA = \"abnormal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_contents(file_path: str, classification: str) -> pd.DataFrame:\n",
    "    \"\"\"Process data file contents.\n",
    "\n",
    "    Reads data from a specific .csv file and extracts the value column.\n",
    "    The function splits filename to Subject ID part and and event number.\n",
    "    These values are added to the dataframe along with classification label.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Full file path to processed file.\n",
    "    classification : str\n",
    "        Classification label of the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Modified Pandas DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    subject_id, event_number = file_name.replace(\".csv\", \"\").split(\"_\")[1:]\n",
    "    subject_id = subject_id.replace(\"ID\", \"\")\n",
    "\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    data[\"event_number\"] = event_number\n",
    "    data[\"subject_id\"] = subject_id\n",
    "    if classification == NORMAL_DATA:\n",
    "        data[\"label\"] = 0\n",
    "        return data\n",
    "    data[\"label\"] = 1\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_directory_contents(directory: str, classification: str) -> pd.DataFrame:\n",
    "    \"\"\"Process all files in a directory.\n",
    "\n",
    "    Iterates over all files in given directory. These files are passed to\n",
    "    get_file_contents() function, which processes each file. Function combines\n",
    "    all processed files into one Pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str\n",
    "        Root directory of the source data.\n",
    "    classification : str\n",
    "        Subdirectory in root, which indicates to correct classification.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Concatenated Pandas DataFrame of all files in same directory.\n",
    "\n",
    "    \"\"\"\n",
    "    full_dataset = []\n",
    "    directory = os.path.join(directory, classification)\n",
    "    for file in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        data = get_file_contents(file_path=file_path, classification=classification)\n",
    "        data.shape\n",
    "        full_dataset.append(data)\n",
    "\n",
    "    return pd.concat(full_dataset, ignore_index=True)\n",
    "\n",
    "\n",
    "def combine_all_data() -> pd.DataFrame:\n",
    "    \"\"\"Combine all data into one DataFrame\n",
    "\n",
    "    Functions calls processing tasks to get all the data together\n",
    "    from their respective directories. Combines all these together.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Combined Normal and Abnormal data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    normal_data = get_directory_contents(DATA_DIRECTORY, NORMAL_DATA)\n",
    "    print(\"Normal data has been processed\\n\")\n",
    "    abnormal_data = get_directory_contents(DATA_DIRECTORY, ABNORMAL_DATA)\n",
    "    print(\"Abnormal data has been processed\\n\")\n",
    "\n",
    "    return pd.concat([normal_data, abnormal_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal data has been processed\n",
      "\n",
      "Abnormal data has been processed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = combine_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of           Lead II event_number subject_id  label\n",
       "0          -0.200          102        105      0\n",
       "1          -0.200          102        105      0\n",
       "2          -0.180          102        105      0\n",
       "3          -0.145          102        105      0\n",
       "4          -0.130          102        105      0\n",
       "...           ...          ...        ...    ...\n",
       "28443595   -0.345           37        215      1\n",
       "28443596   -0.350           37        215      1\n",
       "28443597   -0.320           37        215      1\n",
       "28443598   -0.290           37        215      1\n",
       "28443599   -0.290           37        215      1\n",
       "\n",
       "[28443600 rows x 4 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
